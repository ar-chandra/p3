{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import csv\n",
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import sklearn\n",
    "import json\n",
    "from PIL import ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, ELU, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "from keras.callbacks import Callback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_model_nv():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=final_input_shape,output_shape=final_input_shape))\n",
    "\n",
    "    model.add(Convolution2D(24, 5, 5, border_mode='same', init=\"normal\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Convolution2D(36, 5, 5, border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Convolution2D(48, 5, 5, border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Convolution2D(64, 5, 5, border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(ELU())\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Dense(50))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(ELU())\n",
    "\n",
    "    model.add(Dense(1))\n",
    "        \n",
    "    model.compile(loss='mean_squared_error',optimizer='sgd', metrics=['accuracy'])\n",
    "    #model.evaluate(np.asarray([np.zeros((10))]), np.asarray([np.zeros((20))]))\n",
    "    return model\n",
    "\n",
    "def get_model_ca():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=final_input_shape,output_shape=final_input_shape))\n",
    "\n",
    "    model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def shuffle_arrays(X, y):\n",
    "    size = len(X)\n",
    "    X_shuf = np.empty(shape=X.shape)\n",
    "    y_shuf = np.empty(shape=y.shape)\n",
    "    \n",
    "    index_shuf = np.arange(len(X))\n",
    "    \n",
    "    np.random.shuffle(index_shuf)\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for i in index_shuf:\n",
    "        X_shuf[index] = X[i]\n",
    "        y_shuf[index] = y[i]\n",
    "        index+=1\n",
    "        \n",
    "    return X_shuf, y_shuf   \n",
    "\n",
    "def shuffle_lists(X, y):\n",
    "    \n",
    "    size = len(X)\n",
    "    #print(\"called shuffle_lists\", size)\n",
    "    \n",
    "    X_shuf = []\n",
    "    y_shuf = []\n",
    "    \n",
    "    index_shuf = np.arange(size)\n",
    "    \n",
    "    np.random.shuffle(index_shuf)\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for i in index_shuf:\n",
    "        X_shuf.append(X[i])\n",
    "        y_shuf.append(y[i])\n",
    "        index+=1\n",
    "    \n",
    "    return X_shuf, y_shuf \n",
    "\n",
    "def load_csv():\n",
    "    image_paths= []\n",
    "    steering_angles = []\n",
    "    #print(\"called load_csv\")\n",
    "    with open(path+filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None) \n",
    "\n",
    "        index = 0\n",
    "        for row in reader:\n",
    "           image_paths.append(row[0])\n",
    "           steering_angles.append(float(row[3])) \n",
    "           index+=1\n",
    "    return image_paths, steering_angles\n",
    "\n",
    "def load_data1(image_paths, steering_angles):\n",
    "      \n",
    "    size = len(image_paths)\n",
    "    #print(\"called load_data\", size)\n",
    "    \n",
    "    shape = imread(path+image_paths[0]).shape\n",
    "       \n",
    "    X = np.zeros(shape=(size,final_input_shape[0],final_input_shape[1],final_input_shape[2]))\n",
    "    y = np.zeros(shape=(size,1)).astype(float)\n",
    "    \n",
    "    for i in range(size):\n",
    "        img = imread(path+image_paths[i])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "        if(imgsize != shape):#resize if image size is not per your liking\n",
    "            #print(\"Resizing image\")\n",
    "            img = cv2.resize(img,(imgsize[1],imgsize[0]))\n",
    "\n",
    "        imgarr = img_to_array(img)\n",
    "        \n",
    "        if(crop_s > 0 and crop_e > 0):\n",
    "            X[i] = imgarr[crop_s:crop_e:, :, :]\n",
    "        else:\n",
    "            X[i] = imgarr\n",
    "\n",
    "        y[i] = steering_angles[i]\n",
    "        i+=1\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def data_generator(batch_size=1):\n",
    "    #print(\"called data_generator\")\n",
    "    \n",
    "    image_paths, steering_angles = load_csv()\n",
    "    image_paths, steering_angles = shuffle_lists(image_paths, steering_angles)\n",
    "    while True:\n",
    "       for i in range(0,total,batch_size):\n",
    "           #image_paths, steering_angles = shuffle_lists(image_paths, steering_angles)\n",
    "           #X,y = load_data(image_paths[i:i+batch_size], steering_angles[i:i+batch_size])\n",
    "           image_paths_s, steering_angles_s = shuffle_lists(image_paths[i:i+batch_size], steering_angles[i:i+batch_size])\n",
    "           X,y = load_data(image_paths_s, steering_angles_s)\n",
    "           #print(\"yeilding X\", X[0])\n",
    "           #print(\"yeilding y\", y)\n",
    "           yield (X, y)\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, verbose=1)\n",
    "        print('\\nValidation loss: {}, acc: {}\\n'.format(loss, acc))          \n",
    "        #ModelCheckpoint(\"model-{epoch:02d}.h5\", monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "def load_data(image_paths, steering_angles):\n",
    "   \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    shape = imread(path+image_paths[0]).shape\n",
    "        \n",
    "    for i in range(0,len(image_paths)):\n",
    "        img = imread(path+image_paths[i])\n",
    "        #img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if(imgsize != shape):#resize if image size is not per your liking\n",
    "        #print(\"Resizing image\")\n",
    "            img = cv2.resize(img,(imgsize[1],imgsize[0]))\n",
    "            \n",
    "            \n",
    "        imgarr = img_to_array(img)\n",
    "        \n",
    "        #crop image if needed\n",
    "        if(crop_s > 0 and crop_e > 0):\n",
    "            imgarr = imgarr[crop_s:crop_e:, :, :]\n",
    "        \n",
    "        \n",
    "        x.append(imgarr)\n",
    "        y.append(steering_angles[i])\n",
    "\n",
    "       \n",
    "        #flip images when road is curved\n",
    "        if(steering_angles[i] > 0.1 or steering_angles[i] < -0.1):\n",
    "            print(\"flipping image, St angle is \", steering_angles[i])\n",
    "            x.append(imgarr[::-1])\n",
    "            y.append(steering_angles[i]*-1)\n",
    "        \n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "    return np.array(x), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "       \n",
    "# run the training process\n",
    "path = \"data/\"\n",
    "filename = \"dummy.csv\"\n",
    "model_name = \"iter12\"\n",
    "\n",
    "#Org - 160x320x3\n",
    "#resize - 80% \n",
    "imgsize = (128,256,3)\n",
    "\n",
    "#crop - 72x256x3\n",
    "crop_s = 40\n",
    "crop_e = 112\n",
    "\n",
    "#final\n",
    "final_input_shape = (72,256,3)\n",
    "\n",
    "\n",
    "image_paths, steering_angles = load_csv()\n",
    "\n",
    "total = len(image_paths)\n",
    "batch_size = 5\n",
    "epochs = 2\n",
    "\n",
    "image_paths, steering_angles = shuffle_lists(image_paths, steering_angles)  \n",
    "\n",
    "split = round(0.33*total)\n",
    "\n",
    "X_val = image_paths[0:split]\n",
    "y_val = steering_angles[0:split]\n",
    "\n",
    "\n",
    "X_train = image_paths[split:total]\n",
    "y_train = steering_angles[split:total]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 7\n",
      "14 14\n",
      "7 7\n",
      "['IMG/center_2016_12_01_13_32_45_780.jpg', 'IMG/center_2016_12_01_13_32_45_477.jpg', 'IMG/center_2016_12_01_13_32_45_679.jpg', 'IMG/center_2016_12_01_13_32_43_963.jpg', 'IMG/center_2016_12_01_13_32_45_275.jpg', 'IMG/center_2016_12_01_13_32_45_881.jpg', 'IMG/center_2016_12_01_13_32_45_174.jpg', 'IMG/center_2016_12_01_13_32_46_587.jpg', 'IMG/center_2016_12_01_13_32_46_084.jpg', 'IMG/center_2016_12_01_13_32_44_974.jpg', 'IMG/center_2016_12_01_13_32_45_578.jpg', 'IMG/center_2016_12_01_13_32_46_285.jpg', 'IMG/center_2016_12_01_13_32_44_873.jpg', 'IMG/center_2016_12_01_13_32_45_377.jpg'] [0.1765823, 0.0904655, 0.1765823, 3.0, 0.08089697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1574452, -0.0787459, 0.0, 0.0904655]\n",
      "['IMG/center_2016_12_01_13_32_43_862.jpg', 'IMG/center_2016_12_01_13_32_45_982.jpg', 'IMG/center_2016_12_01_13_32_46_486.jpg', 'IMG/center_2016_12_01_13_32_46_185.jpg', 'IMG/center_2016_12_01_13_32_46_385.jpg', 'IMG/center_2016_12_01_13_32_44_064.jpg', 'IMG/center_2016_12_01_13_32_45_074.jpg'] [0.0, 0.0, -0.0787459, -0.0787459, -0.0787459, 4.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(total, split)\n",
    "\n",
    "print(len(X_train),len(y_train))\n",
    "\n",
    "print(len(X_val),len(y_val))\n",
    "\n",
    "\n",
    "print(X_train,y_train)\n",
    "\n",
    "print(X_val,y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = get_model_nv()\n",
    "#model.summary()  \n",
    "\n",
    "\n",
    "X_test, y_test = load_data(image_paths[1:6], steering_angles[1:6])\n",
    "print(y_test)\n",
    "history = model.fit_generator(data_generator(batch_size), samples_per_epoch = total, nb_epoch = epochs,\n",
    "verbose=1, callbacks=[TestCallback((X_test, y_test))], validation_data=None, class_weight=None, nb_worker=1)\n",
    "\n",
    "# validate\n",
    "print(model.predict(X_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
